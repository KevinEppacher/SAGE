import rclpy
from rclpy.node import Node
from sensor_msgs.msg import Image
from tf2_msgs.msg import TFMessage
from cv_bridge import CvBridge
import cv2
from openfusion_ros.slam import build_slam, BaseSLAM
import numpy as np
from argparse import Namespace
import open3d as o3d
from scipy.spatial.transform import Rotation as R
from geometry_msgs.msg import TransformStamped
from tf2_msgs.msg import TFMessage
from tf_transformations import quaternion_matrix
import tf_transformations
from tf2_ros import Buffer, TransformListener
from openfusion_ros.utils import (
    show_pc, save_pc, get_cmap_legend
)
from sensor_msgs.msg import PointCloud2, PointField
from std_msgs.msg import Header
import sensor_msgs_py.point_cloud2 as pc2
from rosgraph_msgs.msg import Clock
from builtin_interfaces.msg import Time
from visualization_msgs.msg import Marker
# Import PoseArray
from geometry_msgs.msg import Twist, PoseWithCovarianceStamped, PoseArray, Pose

def transform_to_matrix(transform_stamped):
    t = transform_stamped.transform.translation
    q = transform_stamped.transform.rotation
    matrix = quaternion_matrix([q.x, q.y, q.z, q.w])
    matrix[0, 3] = t.x
    matrix[1, 3] = t.y
    matrix[2, 3] = t.z
    return matrix

def convert_ros_to_openfusion_pose(matrix: np.ndarray) -> np.ndarray:
    conversion = np.array([
        [0, 0, 1],  # x_ros → z
        [0, 1, 0],  # y_ros → y
        [1, 0, 0]   # z_ros → x
    ])

    R_ros = matrix[:3, :3]
    t_ros = matrix[:3, 3]

    R_openfusion = conversion @ R_ros
    t_openfusion = conversion @ t_ros

    new_matrix = np.eye(4)
    new_matrix[:3, :3] = R_openfusion
    new_matrix[:3, 3] = t_openfusion

    return new_matrix

def time_to_float(t: Time):
    return t.sec + t.nanosec * 1e-9

def convert_stamp_to_sec(stamp):
    return stamp.sec + stamp.nanosec * 1e-9
    
class OpenFusionNode(Node):
    def __init__(self):
        super().__init__('openfusion_node')
        self.get_logger().info("OpenFusionNode initialized")

        # Initialize variables
        self.frequency = 10
        self.rgb = None
        self.depth = None
        self.pose = None
        self.rgb_stamp = None
        self.depth_stamp = None
        self.pose_stamp = None
        self.latest_clock = None
        self.pose_history = []
        self.bridge = CvBridge()
        np.set_printoptions(precision=3, suppress=True)

        # Publishers and subscribers
        self.tf_buffer = Buffer()
        self.tf_listener = TransformListener(self.tf_buffer, self)
        self.pc_pub = self.create_publisher(PointCloud2, '/openfusion/pointcloud', 10)
        self.pose_pub = self.create_publisher(PoseArray, '/openfusion/pose_array', 10)
        self.clock_sub = self.create_subscription(Clock, '/clock', self.clock_callback, 10)
        self.timer = self.create_timer(1/self.frequency, self.timer_callback)
        self.rgb_sub = self.create_subscription(Image, '/rgb', self.rgb_callback, 10)
        self.depth_sub = self.create_subscription(Image, '/depth', self.depth_callback, 10)
        self.depth_pc_pub = self.create_publisher(PointCloud2, '/openfusion/depth_pointcloud', 10)

        intrinsic = np.array([
            [916.2491, 0.0, 640.0],
            [0.0, 916.2491, 360.0],
            [0.0, 0.0, 1.0]
        ], dtype=np.float64)

        params = {
            'path': '/app/src/OpenFusion/sample/scannet/scene0010_01',
            'depth_scale': 1000.0,
            'depth_max': 5.0,
            'voxel_size': 0.01953125,
            'block_resolution': 8,
            'block_count': 20000,
            'img_size': (640, 480),
            'input_size': (320, 240)
        }

        args = Namespace(
            algo='vlfusion',
            vl='seem',
            data='scannet',
            scene='scene0010_01',
            frames=-1,
            device='cuda:0',
            live=False,
            stream=False,
            save=False,
            load=False,
            host_ip='YOUR IP'
        )

        # self.slam = build_slam(args, intrinsic, params)

    def rgb_callback(self, msg):
        try:
            self.rgb = self.bridge.imgmsg_to_cv2(msg, desired_encoding='bgr8')
            self.rgb_stamp = msg.header.stamp
        except Exception as e:
            self.get_logger().error(f"Failed to convert RGB image: {e}")

    def depth_callback(self, msg):
        try:
            depth_img = self.bridge.imgmsg_to_cv2(msg, desired_encoding='passthrough')
            if depth_img.dtype == np.float32:
                depth_img = (depth_img * 1000.0).astype(np.uint16)
            elif depth_img.dtype != np.uint16:
                self.get_logger().warn(f"Unexpected depth dtype: {depth_img.dtype}")
                return
            self.depth = depth_img
            self.depth_stamp = msg.header.stamp
        except Exception as e:
            self.get_logger().error(f"Failed to convert depth image: {e}")

    def get_pose(self):
        try:
            
            transform = self.tf_buffer.lookup_transform('map', 'camera', self.get_timestamp())
            
            self.pose_stamp = transform.header.stamp
            
            return transform_to_matrix(transform)
        
        except Exception as e:
        
            self.get_logger().warn(f"Transform not available: {e}")
        
            return None

    def get_rgb(self):
        self.rgb_stamp = self.get_timestamp()
        return self.rgb
    
    def get_depth(self):
        self.depth_stamp = self.get_timestamp()
        return self.depth

    def get_timestamp(self):
        return self.latest_clock if self.latest_clock is not None else self.get_clock().now().to_msg()

    def clock_callback(self, msg: Clock):
        current_time = msg.clock
        if self.latest_clock:
            prev = time_to_float(self.latest_clock)
            curr = time_to_float(current_time)
            if curr < prev:
                self.get_logger().warn("Detected rosbag loop! Clearing TF buffer.")
                self.tf_buffer.clear()

        self.latest_clock = current_time

    def publish_pointcloud(self, points, colors):
        if points is None or len(points) == 0:
            self.get_logger().warn("No points to publish")
            return
        colors = np.clip(colors, 0, 1)
        colors_uint8 = (colors * 255).astype(np.uint8)
        rgb_uint32 = (colors_uint8[:, 0].astype(np.uint32) << 16 |
                      colors_uint8[:, 1].astype(np.uint32) << 8 |
                      colors_uint8[:, 2].astype(np.uint32))
        cloud = [(x, y, z, rgb) for (x, y, z), rgb in zip(points, rgb_uint32)]
        fields = [
            PointField(name='x', offset=0, datatype=PointField.FLOAT32, count=1),
            PointField(name='y', offset=4, datatype=PointField.FLOAT32, count=1),
            PointField(name='z', offset=8, datatype=PointField.FLOAT32, count=1),
            PointField(name='rgb', offset=12, datatype=PointField.UINT32, count=1)
        ]
        header = Header()
        header.stamp = self.get_timestamp()
        header.frame_id = 'map'
        pc2_msg = pc2.create_cloud(header, fields, cloud)
        self.pc_pub.publish(pc2_msg)

    def publish_pose_array(self, pose_matrix):
        if pose_matrix is None:
            return

        pose_array = PoseArray()
        pose_array.header.stamp = self.get_timestamp()
        pose_array.header.frame_id = 'map'

        pose = Pose()
        pose.position.x = pose_matrix[0, 3]
        pose.position.y = pose_matrix[1, 3]
        pose.position.z = pose_matrix[2, 3]
        q = tf_transformations.quaternion_from_matrix(pose_matrix)
        pose.orientation.x = q[0]
        pose.orientation.y = q[1]
        pose.orientation.z = q[2]
        pose.orientation.w = q[3]

        self.pose_history.append(pose)
        if len(self.pose_history) > 10:
            self.pose_history.pop(0)

        pose_array.poses = self.pose_history
        self.pose_pub.publish(pose_array)

    def open_fusion_process(self, rgb, depth, pose):
        self.slam.io.update(rgb, depth, pose)
        self.slam.vo()
        self.slam.compute_state(encode_image=True)
        points, colors = self.slam.point_state.get_pc()
        self.publish_pointcloud(points, colors)
        show_pc(points, colors, self.slam.point_state.poses)

    def publish_depth_pointcloud(self, rgb, depth, frame_id='camera'):
        if depth is None or rgb is None:
            self.get_logger().warn("Missing RGB or depth image for depth cloud.")
            return

        height, width = depth.shape
        fx = 916.2491
        fy = 916.2491
        cx = 640.0
        cy = 360.0
        scale = 1000.0  # mm → m

        points = []
        for v in range(0, height, 4):
            for u in range(0, width, 4):
                z = depth[v, u] / scale
                if z == 0:
                    continue
                x = (u - cx) * z / fx
                y = (v - cy) * z / fy
                color = rgb[v, u]
                r, g, b = color
                rgb_value = (int(r) << 16) | (int(g) << 8) | int(b)
                points.append((x, y, z, rgb_value))


        fields = [
            PointField(name='x', offset=0, datatype=PointField.FLOAT32, count=1),
            PointField(name='y', offset=4, datatype=PointField.FLOAT32, count=1),
            PointField(name='z', offset=8, datatype=PointField.FLOAT32, count=1),
            PointField(name='rgb', offset=12, datatype=PointField.UINT32, count=1)
        ]

        header = Header()
        header.stamp = self.get_timestamp()
        header.frame_id = frame_id

        pc2_msg = pc2.create_cloud(header, fields, points)
        self.depth_pc_pub.publish(pc2_msg)

    def timer_callback(self):
        # Get all the images and pose
        pose = self.get_pose()
        rgb = self.get_rgb()
        depth = self.get_depth()

        # Check if any of the images ore pose are None
        if pose is None or rgb is None or depth is None:
            reason = (
                "pose" if pose is None else
                "RGB" if rgb is None else
                "depth"
            )
            self.get_logger().warn(f"Skipping frame: {reason} is None.")
            return

        # Convert the timestamps to seconds
        rgb_time = convert_stamp_to_sec(self.rgb_stamp)
        depth_time = convert_stamp_to_sec(self.depth_stamp)
        pose_time = convert_stamp_to_sec(self.pose_stamp)

        # Check if the timestamps are synchronized
        max_diff = max(abs(rgb_time - depth_time), abs(rgb_time - pose_time), abs(depth_time - pose_time))
        if max_diff > 0.1:
            self.get_logger().warn(f"Timestamps not synchronized (Δ={max_diff:.3f}s). Skipping frame.")
            return

        print(f"Pose \n: {pose}")
        # pose = convert_ros_to_openfusion_pose(pose)
        print(f"Converted Pose \n: {pose}")
        self.publish_pose_array(pose)
        # self.open_fusion_process(rgb, depth, pose)

        print("----------------------------------------------")
        # For debugging purposes
        self.publish_depth_pointcloud(rgb, depth, frame_id='camera')